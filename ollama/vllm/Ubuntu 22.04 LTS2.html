<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>modern的Vitepress文档</title>
    <meta name="description" content="一个vitepress站点">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/docs/assets/style.BCUN5NjH.css" as="style">
    <link rel="preload stylesheet" href="/docs/vp-icons.css" as="style">
    
    <script type="module" src="/docs/assets/app.DeydoWAW.js"></script>
    <link rel="preload" href="/docs/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/docs/assets/chunks/theme.DUAvckyu.js">
    <link rel="modulepreload" href="/docs/assets/chunks/framework.oP1PDRBo.js">
    <link rel="modulepreload" href="/docs/assets/ollama_vllm_Ubuntu 22.04 LTS2.md.D4tQ1ST1.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-96fd1f2d><!--[--><!--]--><!--[--><span tabindex="-1" data-v-fda82a71></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-fda82a71>Skip to content</a><!--]--><!----><header class="VPNav" data-v-96fd1f2d data-v-1e65ffe5><div class="VPNavBar" data-v-1e65ffe5 data-v-74add294><div class="wrapper" data-v-74add294><div class="container" data-v-74add294><div class="title" data-v-74add294><div class="VPNavBarTitle has-sidebar" data-v-74add294 data-v-d8b65c1e><a class="title" href="/docs/" data-v-d8b65c1e><!--[--><!--]--><!--[--><img class="VPImage logo" src="/docs/comet.png" alt data-v-4613ca3b><!--]--><span data-v-d8b65c1e>modern的Vitepress文档</span><!--[--><!--]--></a></div></div><div class="content" data-v-74add294><div class="content-body" data-v-74add294><!--[--><!--]--><div class="VPNavBarSearch search" data-v-74add294><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-74add294 data-v-2ec5bf78><span id="main-nav-aria-label" class="visually-hidden" data-v-2ec5bf78> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/docs/" tabindex="0" data-v-2ec5bf78 data-v-155cbae0><!--[--><span data-v-155cbae0>Home</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-2ec5bf78 data-v-60a38d92><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-60a38d92><span class="text" data-v-60a38d92><!----><span data-v-60a38d92>CAE</span><span class="vpi-chevron-down text-icon" data-v-60a38d92></span></span></button><div class="menu" data-v-60a38d92><div class="VPMenu" data-v-60a38d92 data-v-f010246f><div class="items" data-v-f010246f><!--[--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/CAE/PC%E6%9D%90%E8%B4%A8%E6%8F%90%E6%89%8B%E5%8F%97%E6%8B%89%E5%A4%B1%E6%95%88%E5%88%86%E6%9E%90.html" data-v-d50e348f><!--[--><span data-v-d50e348f>PC材质提手受拉失效分析</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/CAE/PC%E6%9D%90%E8%B4%A8%E6%8F%90%E6%89%8B%E7%9A%84%E6%8B%89%E5%8A%9B%E5%A4%B1%E6%95%88%E5%88%86%E6%9E%90.html" data-v-d50e348f><!--[--><span data-v-d50e348f>PC材质提手的拉力失效分析</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/CAE/21%E8%AE%B2%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91%E5%A4%A7%E7%BA%B2.html" data-v-d50e348f><!--[--><span data-v-d50e348f>21讲二次开发大纲</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/CAE/22%E8%AE%B2set%20puts%20expr%20for%E5%BE%AA%E7%8E%AF.html" data-v-d50e348f><!--[--><span data-v-d50e348f>22讲 set puts expr for循环</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/CAE/23%E8%AE%B2%E5%88%97%E8%A1%A8%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%93%8D%E4%BD%9C%E6%96%B9%E6%B3%95.html" data-v-d50e348f><!--[--><span data-v-d50e348f>23讲列表和字符串的操作方法</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/CAE/24%E8%AE%B2%E6%96%87%E4%BB%B6%E5%AF%B9%E8%AF%9D%E6%A1%86%E7%9A%84%E6%93%8D%E4%BD%9C%E6%96%B9%E6%B3%95.html" data-v-d50e348f><!--[--><span data-v-d50e348f>24讲文件对话框的操作方法</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-2ec5bf78 data-v-60a38d92><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-60a38d92><span class="text" data-v-60a38d92><!----><span data-v-60a38d92>ollama</span><span class="vpi-chevron-down text-icon" data-v-60a38d92></span></span></button><div class="menu" data-v-60a38d92><div class="VPMenu" data-v-60a38d92 data-v-f010246f><div class="items" data-v-f010246f><!--[--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/ollama/Cherry%20Studio%E7%9F%A5%E8%AF%86%E5%BA%93.html" data-v-d50e348f><!--[--><span data-v-d50e348f>Cherry Studio知识库</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-2ec5bf78 data-v-60a38d92><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-60a38d92><span class="text" data-v-60a38d92><!----><span data-v-60a38d92>VitePress</span><span class="vpi-chevron-down text-icon" data-v-60a38d92></span></span></button><div class="menu" data-v-60a38d92><div class="VPMenu" data-v-60a38d92 data-v-f010246f><div class="items" data-v-f010246f><!--[--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/vitepress/zh/guide/what-is-vitepress.html" data-v-d50e348f><!--[--><span data-v-d50e348f>VitePress</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/vitepress/zh/reference/site-config.html" data-v-d50e348f><!--[--><span data-v-d50e348f>参考</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/vitepress/haha.html" data-v-d50e348f><!--[--><span data-v-d50e348f>哈哈</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuGroup" data-v-f010246f data-v-18bc7ae6><p class="title" data-v-18bc7ae6>vitepress</p><!--[--><!--[--><div class="VPMenuLink" data-v-18bc7ae6 data-v-d50e348f><a class="VPLink link" href="/docs/vitepress/%E9%83%A8%E7%BD%B2/VitePress+Github%20Pages%E8%AF%A6%E7%BB%86v1.6.3.html" data-v-d50e348f><!--[--><span data-v-d50e348f>VitePress+Github Pages详细v1.6.3</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-18bc7ae6 data-v-d50e348f><a class="VPLink link" href="/docs/vitepress/%E9%83%A8%E7%BD%B2/VitePress%E9%83%A8%E7%BD%B2v1.6.3.html" data-v-d50e348f><!--[--><span data-v-d50e348f>VitePress部署v1.6.3</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-18bc7ae6 data-v-d50e348f><a class="VPLink link" href="/docs/vitepress/%E9%83%A8%E7%BD%B2/sidebar%E5%8D%95%E7%8B%AC%E6%8A%BD%E7%A6%BB%E6%88%90%E6%96%87%E4%BB%B6.html" data-v-d50e348f><!--[--><span data-v-d50e348f>sidebar单独抽离成文件</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-f010246f data-v-18bc7ae6><p class="title" data-v-18bc7ae6>vitepress</p><!--[--><!--[--><div class="VPMenuLink" data-v-18bc7ae6 data-v-d50e348f><a class="VPLink link" href="/docs/vuepress/A_Node.js%E5%AE%89%E8%A3%85.html" data-v-d50e348f><!--[--><span data-v-d50e348f>A_Node.js安装</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-18bc7ae6 data-v-d50e348f><a class="VPLink link" href="/docs/vuepress/B_npm%E9%95%9C%E5%83%8F%E7%AB%99.html" data-v-d50e348f><!--[--><span data-v-d50e348f>B_npm镜像站</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-18bc7ae6 data-v-d50e348f><a class="VPLink link" href="/docs/vuepress/C_vuepress@1.9.10.html" data-v-d50e348f><!--[--><span data-v-d50e348f>C_vuepress@1.9.10</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/vitepress/markdown-examples.html" data-v-d50e348f><!--[--><span data-v-d50e348f>Examples</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/vitepress/api-examples.html" data-v-d50e348f><!--[--><span data-v-d50e348f>api-examples</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-2ec5bf78 data-v-60a38d92><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-60a38d92><span class="text" data-v-60a38d92><!----><span data-v-60a38d92>笔记</span><span class="vpi-chevron-down text-icon" data-v-60a38d92></span></span></button><div class="menu" data-v-60a38d92><div class="VPMenu" data-v-60a38d92 data-v-f010246f><div class="items" data-v-f010246f><!--[--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/notes/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html" data-v-d50e348f><!--[--><span data-v-d50e348f>git常用命令</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/notes/%E5%B8%B8%E7%94%A8Markdown%E8%AF%AD%E6%B3%95.html" data-v-d50e348f><!--[--><span data-v-d50e348f>常用Markdown</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/notes/%E4%B8%8B%E8%BD%BD%E5%92%8C%E5%AE%89%E8%A3%85Pandoc_Windows%E7%89%88%E6%9C%AC.html" data-v-d50e348f><!--[--><span data-v-d50e348f>下载和安装Pandoc_Windows版本</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/notes/GitHub%E4%B8%8A%E5%88%A0%E9%99%A4%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E4%B8%AA%E5%88%AB%E6%96%87%E4%BB%B6.html" data-v-d50e348f><!--[--><span data-v-d50e348f>GitHub</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/notes/%E5%AE%89%E8%A3%85git.html" data-v-d50e348f><!--[--><span data-v-d50e348f>安装git</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/notes/note.html" data-v-d50e348f><!--[--><span data-v-d50e348f>note</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/notes/Pandoc%E5%91%BD%E4%BB%A4.html" data-v-d50e348f><!--[--><span data-v-d50e348f>Pandoc命令</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-2ec5bf78 data-v-60a38d92><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-60a38d92><span class="text" data-v-60a38d92><!----><span data-v-60a38d92>前端</span><span class="vpi-chevron-down text-icon" data-v-60a38d92></span></span></button><div class="menu" data-v-60a38d92><div class="VPMenu" data-v-60a38d92 data-v-f010246f><div class="items" data-v-f010246f><!--[--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/frontEnd/ajax/Day01_AJAX%E5%85%A5%E9%97%A8.html" data-v-d50e348f><!--[--><span data-v-d50e348f>Day01_AJAX入门</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/frontEnd/vue/vue.html" data-v-d50e348f><!--[--><span data-v-d50e348f>vue</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/frontEnd/JavaScript/JavaScript.html" data-v-d50e348f><!--[--><span data-v-d50e348f>JavaScript</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/frontEnd/Node.js/01%E5%88%9D%E8%AF%86Node.js%E4%B8%8E%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97.html" data-v-d50e348f><!--[--><span data-v-d50e348f>01初识Node.js与内置模块</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/frontEnd/Node.js/02_%E6%A8%A1%E5%9D%97%E5%8C%96.html" data-v-d50e348f><!--[--><span data-v-d50e348f>02_模块化</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/frontEnd/Node.js/03_Express.html" data-v-d50e348f><!--[--><span data-v-d50e348f>03_Express</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/frontEnd/Node.js/04_%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81.html" data-v-d50e348f><!--[--><span data-v-d50e348f>04_数据库与身份认证</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/frontEnd/Node.js/05_ev_api_server.html" data-v-d50e348f><!--[--><span data-v-d50e348f>05_ev_api_server</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/frontEnd/Node.js/06_ev_api_server.html" data-v-d50e348f><!--[--><span data-v-d50e348f>06_ev_api_server</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/frontEnd/else/2024%E5%B9%B4%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF%E5%9B%BE.html" data-v-d50e348f><!--[--><span data-v-d50e348f>2024年前端学习路线图</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/frontEnd/else/else.html" data-v-d50e348f><!--[--><span data-v-d50e348f>else</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-2ec5bf78 data-v-60a38d92><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-60a38d92><span class="text" data-v-60a38d92><!----><span data-v-60a38d92>后端</span><span class="vpi-chevron-down text-icon" data-v-60a38d92></span></span></button><div class="menu" data-v-60a38d92><div class="VPMenu" data-v-60a38d92 data-v-f010246f><div class="items" data-v-f010246f><!--[--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/backEnd/spring.html" data-v-d50e348f><!--[--><span data-v-d50e348f>spring</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/backEnd/java.html" data-v-d50e348f><!--[--><span data-v-d50e348f>java</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-2ec5bf78 data-v-60a38d92><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-60a38d92><span class="text" data-v-60a38d92><!----><span data-v-60a38d92>blogs</span><span class="vpi-chevron-down text-icon" data-v-60a38d92></span></span></button><div class="menu" data-v-60a38d92><div class="VPMenu" data-v-60a38d92 data-v-f010246f><div class="items" data-v-f010246f><!--[--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/blogs/coding-001.html" data-v-d50e348f><!--[--><span data-v-d50e348f>编程日志</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/blogs/food-001/" data-v-d50e348f><!--[--><span data-v-d50e348f>美食记录</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/blogs/garden-001/" data-v-d50e348f><!--[--><span data-v-d50e348f>园艺笔记</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/blogs/health-001.html" data-v-d50e348f><!--[--><span data-v-d50e348f>健康生活</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/blogs/life-001.html" data-v-d50e348f><!--[--><span data-v-d50e348f>生活随笔</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/blogs/movie-001.html" data-v-d50e348f><!--[--><span data-v-d50e348f>影视评论</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/blogs/music-001.html" data-v-d50e348f><!--[--><span data-v-d50e348f>音乐分享</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/blogs/photo-001.html" data-v-d50e348f><!--[--><span data-v-d50e348f>摄影作品</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/blogs/reading-001.html" data-v-d50e348f><!--[--><span data-v-d50e348f>读书笔记</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-f010246f data-v-d50e348f><a class="VPLink link" href="/docs/blogs/travel-001.html" data-v-d50e348f><!--[--><span data-v-d50e348f>旅行日记</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-74add294 data-v-a45243dd><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-a45243dd data-v-93fba70d data-v-5fe11359><span class="check" data-v-5fe11359><span class="icon" data-v-5fe11359><!--[--><span class="vpi-sun sun" data-v-93fba70d></span><span class="vpi-moon moon" data-v-93fba70d></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-74add294 data-v-7ca579ed data-v-87882f81><!--[--><a class="VPSocialLink no-icon" href="https://github.com/vuejs/vitepress" aria-label="github" target="_blank" rel="noopener" data-v-87882f81 data-v-a01ee93b><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-74add294 data-v-b1ad3f78 data-v-60a38d92><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-60a38d92><span class="vpi-more-horizontal icon" data-v-60a38d92></span></button><div class="menu" data-v-60a38d92><div class="VPMenu" data-v-60a38d92 data-v-f010246f><!----><!--[--><!--[--><!----><div class="group" data-v-b1ad3f78><div class="item appearance" data-v-b1ad3f78><p class="label" data-v-b1ad3f78>Appearance</p><div class="appearance-action" data-v-b1ad3f78><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b1ad3f78 data-v-93fba70d data-v-5fe11359><span class="check" data-v-5fe11359><span class="icon" data-v-5fe11359><!--[--><span class="vpi-sun sun" data-v-93fba70d></span><span class="vpi-moon moon" data-v-93fba70d></span><!--]--></span></span></button></div></div></div><div class="group" data-v-b1ad3f78><div class="item social-links" data-v-b1ad3f78><div class="VPSocialLinks social-links-list" data-v-b1ad3f78 data-v-87882f81><!--[--><a class="VPSocialLink no-icon" href="https://github.com/vuejs/vitepress" aria-label="github" target="_blank" rel="noopener" data-v-87882f81 data-v-a01ee93b><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-74add294 data-v-da3508b2><span class="container" data-v-da3508b2><span class="top" data-v-da3508b2></span><span class="middle" data-v-da3508b2></span><span class="bottom" data-v-da3508b2></span></span></button></div></div></div></div><div class="divider" data-v-74add294><div class="divider-line" data-v-74add294></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-96fd1f2d data-v-8ea7aa6c><div class="container" data-v-8ea7aa6c><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-8ea7aa6c><span class="vpi-align-left menu-icon" data-v-8ea7aa6c></span><span class="menu-text" data-v-8ea7aa6c>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-8ea7aa6c data-v-d6548d6b><button data-v-d6548d6b>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-96fd1f2d data-v-31c52f82><div class="curtain" data-v-31c52f82></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-31c52f82><span class="visually-hidden" id="sidebar-aria-label" data-v-31c52f82> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-632cad1e><section class="VPSidebarItem level-0" data-v-632cad1e data-v-7d450594><!----><div class="items" data-v-7d450594><!--[--><div class="VPSidebarItem level-1 is-link" data-v-7d450594 data-v-7d450594><div class="item" data-v-7d450594><div class="indicator" data-v-7d450594></div><a class="VPLink link link" href="/docs/ollama/Ollama.html" data-v-7d450594><!--[--><p class="text" data-v-7d450594>Ollama</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7d450594 data-v-7d450594><div class="item" data-v-7d450594><div class="indicator" data-v-7d450594></div><a class="VPLink link link" href="/docs/ollama/Cherry%20Studio%E7%9F%A5%E8%AF%86%E5%BA%93.html" data-v-7d450594><!--[--><p class="text" data-v-7d450594>Cherry Studio知识库</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7d450594 data-v-7d450594><div class="item" data-v-7d450594><div class="indicator" data-v-7d450594></div><a class="VPLink link link" href="/docs/ollama/InternLM2%E4%B9%A6%E7%94%9F%E6%B5%A6%E8%AF%AD.html" data-v-7d450594><!--[--><p class="text" data-v-7d450594>InternLM2书生浦语</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7d450594 data-v-7d450594><div class="item" data-v-7d450594><div class="indicator" data-v-7d450594></div><a class="VPLink link link" href="/docs/ollama/Llama%203.1%20%E7%BB%BC%E5%90%88%E6%8C%87%E5%8D%97.html" data-v-7d450594><!--[--><p class="text" data-v-7d450594>Llama 3.1 综合指南</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7d450594 data-v-7d450594><div class="item" data-v-7d450594><div class="indicator" data-v-7d450594></div><a class="VPLink link link" href="/docs/ollama/%E4%BB%8E%E9%9B%B6%E5%88%B0%E4%B8%80%EF%BC%8C%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%A5%87%E5%A6%99%E4%B8%96%E7%95%8C.html" data-v-7d450594><!--[--><p class="text" data-v-7d450594>从零到一，深入浅出大语言模型的奇妙世界</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7d450594 data-v-7d450594><div class="item" data-v-7d450594><div class="indicator" data-v-7d450594></div><a class="VPLink link link" href="/docs/ollama/Prompt%E6%8F%90%E7%A4%BA%E8%AF%8D%E4%BC%98%E5%8C%96%E5%8E%9F%E5%88%99.html" data-v-7d450594><!--[--><p class="text" data-v-7d450594>Prompt提示词优化原则</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-96fd1f2d data-v-c5988ff6><div class="VPDoc has-sidebar has-aside" data-v-c5988ff6 data-v-4b99b89c><!--[--><!--]--><div class="container" data-v-4b99b89c><div class="aside" data-v-4b99b89c><div class="aside-curtain" data-v-4b99b89c></div><div class="aside-container" data-v-4b99b89c><div class="aside-content" data-v-4b99b89c><div class="VPDocAside" data-v-4b99b89c data-v-b983f4cb><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-b983f4cb data-v-481df145><div class="content" data-v-481df145><div class="outline-marker" data-v-481df145></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-481df145>文章目录</div><ul class="VPDocOutlineItem root" data-v-481df145 data-v-d9098fbd><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-b983f4cb></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-4b99b89c><div class="content-container" data-v-4b99b89c><!--[--><!--]--><main class="main" data-v-4b99b89c><div style="position:relative;" class="vp-doc _docs_ollama_vllm_Ubuntu%2022_04%20LTS2" data-v-4b99b89c><div><p>我们介绍了我们的第一代推理模型，DeepSeek-R1-Zero和DeepSeek-R1。DeepSeek-R1-Zero是一种通过大规模强化学习（RL）训练的模型，没有监督微调（SFT）作为初步步骤，在推理方面表现出卓越的性能。有了强化学习，DeepSeek-R1-Zero自然会出现许多强大而有趣的推理行为。然而，DeepSeek-R1-Zero遇到了无休止的重复、可读性差和语言混合等挑战。为了解决这些问题并进一步提高推理性能，我们引入了DeepSeek-R1，它在RL之前合并了冷启动数据。DeepSeek-R1在数学、代码和推理任务上实现了与OpenAI-o 1相当的性能。为了支持研究社区，我们拥有开源的DeepSeek-R1-Zero、DeepSeek-R1以及基于Llama和Qwen的从DeepSeek-R1中提炼出来的六个密集模型。DeepSeek-R1-Distill-Qwen-32 B在各种基准测试中的表现优于OpenAI-o 1-mini，为密集模型实现了新的最先进的结果。</p><p><strong>后训练：基于基础模型的大规模强化学习</strong></p><p>我们直接将强化学习（RL）应用于基础模型，而不依赖于监督微调（SFT）作为初步步骤。该方法允许模型探索解决复杂问题的思路链（CoT），从而开发出DeepSeek-R1-Zero。DeepSeek-R1-Zero展示了自我验证、反射和生成长CoT等功能，标志着研究界的一个重要里程碑。值得注意的是，这是第一个验证LLM的推理能力可以纯粹通过RL来激励，而不需要SFT的开放式研究。这一突破为该领域的未来发展铺平了道路。</p><p>我们介绍了我们开发DeepSeek-R1的管道。该流水线包括两个RL阶段，旨在发现改进的推理模式并与人类偏好保持一致，以及两个SFT阶段，用作模型的推理和非推理能力的种子。我们相信，这条管道将通过创造更好的模式而使行业受益。</p><p><strong>蒸馏</strong>Distillation**：更小的模型也可以是强大的**</p><p>我们证明了大模型的推理模式可以被提炼成小模型，从而比通过RL在小模型上发现的推理模式具有更好的性能。开源的DeepSeek-R1及其API将使研究社区在未来提取更好的更小的模型。</p><p>使用DeepSeek-R1生成的推理数据，我们微调了几个在研究界广泛使用的密集模型。评估结果表明，提取的较小密度模型在基准测试中表现出色。我们向社区开放了基于Qwen2.5和Llama 3系列的1.5B、7 B、8B、14 B、32 B和70 B检查点的源代码。</p><p>DeepSeek-R1-Zero DeepSeek-R1基于DeepSeek-V3-Base进行训练。有关模型架构的更多详细信息，请参阅<a href="https://github.com/deepseek-ai/DeepSeek-V3" target="_blank" rel="noreferrer">DeepSeek-V3</a>存储库。</p><p>DeepSeek-R1-Distill模型基于开源模型，使用DeepSeek-R1生成的样本进行了微调。我们稍微更改了它们的配置和标记化器。请使用我们的设置来运行这些模型。</p><p>对于我们的所有模型，最大生成长度设置为32，768个令牌。对于需要采样的基准测试，我们使用0.60.60.6的温度，0.950.950.95的top-p值，并为每个查询生成64个响应以估计pass@1。</p><p>你可以在DeepSeek的官方网站上与DeepSeek-R1聊天：，并打开按钮“DeepThink”</p><p>我们还在DeepSeek平台上提供OpenAI兼容的API</p><h2 id="_6-如何在本地运行" tabindex="-1">6.如何在本地运行 <a class="header-anchor" href="#_6-如何在本地运行" aria-label="Permalink to &quot;6.如何在本地运行&quot;">​</a></h2><p>DeepSeek-R1-Distill模型可以以与Qwen或Llama模型相同的方式使用。</p><p>例如，您可以使用vLLM轻松启动服务：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-32B </span></span>
<span class="line"><span>--tensor-parallel-size 2 </span></span>
<span class="line"><span>--max-model-len 32768 </span></span>
<span class="line"><span>--enforce-eager</span></span></code></pre></div><h3 id="使用建议" tabindex="-1">使用建议 <a class="header-anchor" href="#使用建议" aria-label="Permalink to &quot;使用建议&quot;">​</a></h3><p><strong>我们建议在使用DeepSeek-R1系列模型时遵守以下配置，包括基准测试，以实现预期性能：</strong></p><p>将温度设置在0.5-0.7（推荐0.6）的范围内，以防止无休止的重复或不连贯的输出。</p><p><strong>避免添加系统提示符;所有指令都应包含在用户提示符中。</strong></p><p>对于数学问题，建议在提示中包含一个指令，例如：“请逐步推理，并将您的最终答案放在\box{}中。”</p><p>在评估模型性能时，建议进行多次测试并对结果进行平均。</p><p>此外，我们观察到DeepSeek-R1系列模型在响应某些查询时倾向于绕过思维模式（即输出“&lt;思考&gt;\n\n&lt;/思考&gt;”），这可能会对模型的性能产生不利影响。为了确保模型进行彻底的推理，我们建议强制模型在每个输出的开头使用“&lt;思考&gt;\n”来启动其响应</p><h4 id="_1-确认windows的nvidia驱动已安装" tabindex="-1">1.<strong>确认Windows的NVIDIA驱动已安装</strong> <a class="header-anchor" href="#_1-确认windows的nvidia驱动已安装" aria-label="Permalink to &quot;1.**确认Windows的NVIDIA驱动已安装**&quot;">​</a></h4><ul><li>在Windows中打开 <strong>NVIDIA控制面板</strong> → 左下角 <strong>系统信息</strong> → 检查驱动版本是否为 <strong>CUDA 12.1+</strong>（需支持WSL GPU）。</li><li>若未安装，前往<a href="https://www.nvidia.com/Download/index.aspx" target="_blank" rel="noreferrer">NVIDIA官网</a>下载最新驱动。</li></ul><h4 id="配置wsl环境" tabindex="-1"><strong>配置WSL环境</strong> <a class="header-anchor" href="#配置wsl环境" aria-label="Permalink to &quot;**配置WSL环境**&quot;">​</a></h4><ul><li><strong>启用WSL</strong>：在PowerShell（管理员模式）中执行：</li></ul><div class="language-powershell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">powershell</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">wsl </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">--</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">install </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">d Ubuntu</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">22.04</span></span></code></pre></div><p><strong>安装NVIDIA驱动</strong>：确保Windows已安装适配的NVIDIA驱动（如CUDA 12.1+）</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>正在安装: Ubuntu 22.04 LTS</span></span>
<span class="line"><span>无法从 Microsoft Store 安装 Ubuntu-22.04: 与服务器的连接意外终止</span></span>
<span class="line"><span>正在尝试 Web 下载...</span></span>
<span class="line"><span>正在下载: Ubuntu 22.04 LTS</span></span>
<span class="line"><span>正在安装: Ubuntu 22.04 LTS</span></span>
<span class="line"><span>已安装 Ubuntu 22.04 LTS。</span></span>
<span class="line"><span>正在启动 Ubuntu 22.04 LTS...</span></span>
<span class="line"><span>Installing, this may take a few minutes...</span></span>
<span class="line"><span>Please create a default UNIX user account. The username does not need to match your Windows username.</span></span>
<span class="line"><span>For more information visit: https://aka.ms/wslusers</span></span>
<span class="line"><span>Enter new UNIX username: modern</span></span>
<span class="line"><span>^[[B^[[B^[[B^[[A^[[A</span></span>
<span class="line"><span>New password:</span></span>
<span class="line"><span>Retype new password:</span></span>
<span class="line"><span>passwd: password updated successfully</span></span>
<span class="line"><span>123</span></span>
<span class="line"><span>Installation successful!</span></span>
<span class="line"><span></span></span>
<span class="line"><span>To run a command as administrator (user &quot;root&quot;), use &quot;sudo &lt;command&gt;&quot;.</span></span>
<span class="line"><span>See &quot;man sudo_root&quot; for details.</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Welcome to Ubuntu 22.04.2 LTS (GNU/Linux 5.15.167.4-microsoft-standard-WSL2 x86_64)</span></span>
<span class="line"><span></span></span>
<span class="line"><span> * Documentation:  https://help.ubuntu.com</span></span>
<span class="line"><span> * Management:     https://landscape.canonical.com</span></span>
<span class="line"><span> * Support:        https://ubuntu.com/advantage</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span>This message is shown once a day. To disable it please create the</span></span>
<span class="line"><span>/home/modern/.hushlogin file.</span></span></code></pre></div><p>检查已安装的发行版列表：</p><div class="language-powershell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">powershell</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">wsl </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">l </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">v  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 列出所有发行版及其状态（需为 &quot;Running&quot; 或 &quot;Stopped&quot;）</span></span></code></pre></div><p>若列表为空，需重新安装发行版（从 Microsoft Store 下载）。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>  NAME            STATE           VERSION</span></span>
<span class="line"><span>* Ubuntu-22.04    Running         2</span></span></code></pre></div><p>在 WSL 中直接访问 Windows 文件：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>cd /mnt/c/Users/你的用户名  # 例如进入 C 盘用户目录</span></span></code></pre></div><p>彻底卸载命令：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>wsl --unregister Ubuntu-22.04</span></span></code></pre></div><p>进入WSL</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>WSL</span></span></code></pre></div><p><strong>在WSL中安装CUDA Toolkit</strong></p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 进入WSL的Ubuntu终端，依次执行：</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">wget</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> mv</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> cuda-wsl-ubuntu.pin</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/apt/preferences.d/cuda-repository-pin-600</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">wget</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda-repo-wsl-ubuntu-12-1-local_12.1.1-1_amd64.deb</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> dpkg</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -i</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> cuda-repo-wsl-ubuntu-12-1-local_12.1.1-1_amd64.deb</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> cp</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /var/cuda-repo-wsl-ubuntu-12-1-local/cuda-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">*</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">-keyring.gpg</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/share/keyrings/</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> apt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> update</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> apt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> cuda-toolkit-12-1</span></span></code></pre></div><p><strong>在 WSL2 中安装CUDA</strong>‌</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 安装 CUDA（需先安装 Windows 版 NVIDIA 驱动）</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">wget</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> dpkg</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -i</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> cuda-keyring_1.1-1_all.deb</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> apt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> update</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> apt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> cuda-toolkit-12-1</span></span></code></pre></div><h2 id="_2-安装python与依赖" tabindex="-1">2.安装Python与依赖** <a class="header-anchor" href="#_2-安装python与依赖" aria-label="Permalink to &quot;2.安装Python与依赖**&quot;">​</a></h2><p>在WSL中安装Python 3.8+，并配置虚拟环境：</p><p><strong>更新系统包列表</strong> 进入 WSL 终端，执行：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>sudo apt update &amp;&amp; sudo apt upgrade -y      #确保系统的软件包列表是最新的</span></span></code></pre></div><h5 id="通过系统包管理器安装-推荐-ubuntu-20-04-用户" tabindex="-1"><strong>通过系统包管理器安装（推荐 Ubuntu 20.04 用户）</strong> <a class="header-anchor" href="#通过系统包管理器安装-推荐-ubuntu-20-04-用户" aria-label="Permalink to &quot;**通过系统包管理器安装（推荐 Ubuntu 20.04 用户）**&quot;">​</a></h5><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> apt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> python3-pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> build-essential</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>sudo apt install ca-certificates apt-transport-https software-properties-common lsb-release -y</span></span></code></pre></div><p><strong>更新软件包列表并安装Python 3.11</strong>：</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> apt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> update</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> apt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> python3.11</span></span></code></pre></div><p><strong>验证安装</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>python3.11 --version</span></span></code></pre></div><p>Python 3.11.0rc1</p><h3 id="安装包管理工具pip" tabindex="-1">安装包管理工具pip <a class="header-anchor" href="#安装包管理工具pip" aria-label="Permalink to &quot;安装包管理工具pip&quot;">​</a></h3><p>pip是Python的包管理工具，用于安装和管理Python包。可以使用以下命令安装pip：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>sudo apt install python3.10-venv  # Ubuntu 22.04 默认 Python 版本为 3.10</span></span>
<span class="line"><span>sudo apt install python3-pip -y</span></span></code></pre></div><p>sudo apt install python3.8 python3-pip</p><p>安装完成后，可以通过以下命令验证pip是否安装成功：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>pip3 --version</span></span></code></pre></div><p>pip 22.0.2 from /usr/lib/python3/dist-packages/pip (python 3.10)</p><h4 id="三、配置虚拟环境" tabindex="-1"><strong>三、配置虚拟环境</strong> <a class="header-anchor" href="#三、配置虚拟环境" aria-label="Permalink to &quot;**三、配置虚拟环境**&quot;">​</a></h4><p><strong>创建虚拟环境</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>python3 -m venv venv   # 在项目目录中执行</span></span></code></pre></div><p><strong>激活环境</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>source venv/bin/activate  # 激活虚拟环境</span></span></code></pre></div><p>提示符变为 <code>(.venv) $</code> 表示激活成功。</p><p><code>提示符变为(venv) modern@DESKTOP-GQCI0GM:~$</code>表示激活成功。</p><p><strong>安装依赖</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>pip install -r requirements.txt</span></span></code></pre></div><p><strong>pip 安装缓慢</strong></p><p>更换国内镜像源：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</span></span></code></pre></div><p><strong>验证 CUDA 支持</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>nvidia-smi  # 应显示 GPU 状态</span></span></code></pre></div><h3 id="步骤-3-安装vllm和模型依赖" tabindex="-1"><strong>步骤 3：安装vLLM和模型依赖</strong> <a class="header-anchor" href="#步骤-3-安装vllm和模型依赖" aria-label="Permalink to &quot;**步骤 3：安装vLLM和模型依赖**&quot;">​</a></h3><p><strong>安装vLLM（需CUDA 12.1）</strong></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># Install vLLM from pip:</span></span>
<span class="line"><span>pip install vllm -i https://pypi.tuna.tsinghua.edu.cn/simple  # 使用清华镜像加速</span></span></code></pre></div><h4 id="方法3-安装flash-attention优化" tabindex="-1"><strong>方法3：安装Flash Attention优化</strong> <a class="header-anchor" href="#方法3-安装flash-attention优化" aria-label="Permalink to &quot;**方法3：安装Flash Attention优化**&quot;">​</a></h4><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># 在WSL虚拟环境中执行</span></span>
<span class="line"><span>pip uninstall -y vllm</span></span>
<span class="line"><span>pip install vllm[flash-attn]  # 安装含Flash Attention的版本</span></span></code></pre></div><p><strong>可选：安装Flash Attention优化</strong></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>pip install flash-attn --no-build-isolation  # 提升推理速度（需GPU支持）</span></span></code></pre></div><h3 id="步骤-4-下载deepseek-r1-14b模型" tabindex="-1"><strong>步骤 4：下载DeepSeek-R1 14B模型</strong> <a class="header-anchor" href="#步骤-4-下载deepseek-r1-14b模型" aria-label="Permalink to &quot;**步骤 4：下载DeepSeek-R1 14B模型**&quot;">​</a></h3><p>vLLM支持多种主流的大模型格式，包括但不限于以下这些：</p><ul><li><strong>Aquila</strong></li><li><strong>Baichuan</strong></li><li><strong>BLOOM</strong></li><li><strong>Falcon</strong></li><li><strong>GPT-2</strong></li><li><strong>GPT BigCode</strong></li><li><strong>GPT-J</strong></li><li><strong>GPT-NeoX</strong></li><li><strong>InternLM</strong></li><li><strong>LLaMA</strong></li><li><strong>Mistral</strong></li><li><strong>MPT</strong></li><li><strong>OPT</strong></li><li><strong>Qwen</strong></li></ul><p>完整的支持模型列表可以查看vLLM的官方文档</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>pip install modelscope</span></span>
<span class="line"><span>export MODEL_DIR=/home/modern/models  # 替换为你的模型存储路径  # 确保此路径存在且可写</span></span>
<span class="line"><span>modelscope download --model deepseek-ai/DeepSeek-R1-Distill-Qwen-14B --local_dir $MODEL_DIR</span></span>
<span class="line"><span>modelscope download --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B --cache_dir $MODEL_DIR</span></span>
<span class="line"><span>modelscope download --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B --cache_dir /home/modern/models</span></span>
<span class="line"><span>modelscope download --model Qwen/Qwen2.5-Coder-7B-Instruct-AWQ --cache_dir /home/modern/models</span></span>
<span class="line"><span>#模型文件将被下载在&#39;cache_dir/Qwen/Qwen2-7b&#39;</span></span>
<span class="line"><span>模型文件将被下载在&#39;./local_dir&#39;</span></span></code></pre></div><p>下载单个文件到指定本地文件夹（以下载README.md到当前路径下“dir”目录为例）</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>modelscope download --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B README.md --local_dir ./dir</span></span></code></pre></div><p>无论是使用命令行还是ModelScope SDK，默认模型会下载到<code>~/.cache/modelscope/hub</code>目录下。如果需要修改cache目录，可以手动指定环境变量：MODELSCOPE_CACHE，指定后，模型将下载到该环境变量指定的目录中。</p><p>若下载慢，可使用Hugging Face镜像（修改<code>~/.bashrc</code>）：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>export HF_ENDPOINT=https://hf-mirror.com</span></span></code></pre></div><p>在你的用户主目录下创建一个<code>models</code>文件夹。在使用vLLM加载模型时，只需要指定模型所在目录的路径即可。例如，如果你的模型存放在<code>/home/your_username/models/llama-7b</code>目录下，那么在代码中可以这样指定模型路径</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>clear           #清屏</span></span></code></pre></div><h3 id="步骤-5-启动vllm推理服务" tabindex="-1"><strong>步骤 5：启动vLLM推理服务</strong> <a class="header-anchor" href="#步骤-5-启动vllm推理服务" aria-label="Permalink to &quot;**步骤 5：启动vLLM推理服务**&quot;">​</a></h3><p><strong>启动服务（根据显存调整参数）</strong>（关键参数说明）</p><p>--max-model-len 32768</p><ul><li>支持长达32k tokens的上下文（如长文档分析、代码生成）</li><li>显存消耗警告：32k序列的KV缓存需要约20GB显存（单卡），需双卡并行或使用A100 80GB。</li><li>必须处理<strong>超过2k的极长文本</strong>，且拥有双A100/A800。</li><li>显存不足（如单卡16GB）但需要勉强运行，此时需降低<code>--max-model-len</code>。</li></ul><p>--max-model-len=2048</p><ul><li>适合对话、摘要等常规任务（上下文≤2k）。</li><li><strong>显存优化</strong>：显存占用降低至8-10GB，轻松适配消费级显卡。</li></ul><p>依赖vLLM默认策略（通常0.9），但在极端长上下文下可能仍需手动调整。</p><p>--enforce-eager禁用CUDA Graph加速，可能降低推理速度（10-20%），仅建议在<strong>调试内存错误</strong>时启用。</p><p>--port=8102自定义端口便于多服务隔离，无性能影响。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># Load and run the model:</span></span>
<span class="line"><span>//Qwen2.5-Coder-7B-Instruct-AWQ</span></span>
<span class="line"><span>vllm serve  /home/modern/models/Qwen/Qwen2.5-Coder-7B-Instruct-AWQ  --tensor-parallel-size 1 --max-model-len 4096  --gpu-memory-utilization 0.9  --quantization awq --port=8102   --trust-remote-code  # 必须添加 </span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span>  --trust-remote-code  # 必须添加 </span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span>(1) 启用批处理加速</span></span>
<span class="line"><span>  --enable-batch \</span></span>
<span class="line"><span>  --max-num-batched-tokens 4096</span></span>
<span class="line"><span></span></span>
<span class="line"><span>  --tensor-parallel-size 1 \                # GPU 并行数（根据 GPU 数量调整）</span></span>
<span class="line"><span>  --max-model-len 4096 \                    # 最大上下文长度</span></span>
<span class="line"><span>  --gpu-memory-utilization 0.9              # GPU 显存利用率</span></span>
<span class="line"><span>  --quantization awq \                      # 指定 AWQ 量化</span></span>
<span class="line"><span>  --trust-remote-code  # 必须添加</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>#tensor-parallel-size 2，这意味着它将模型在两张GPU上进行张量并行处理。</span></span>
<span class="line"><span># 假设模型路径为 /home/modern/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B</span></span>
<span class="line"><span># 提高显存利用率至合理范围（0.7-0.9）</span></span>
<span class="line"><span>CUDA_VISIBLE_DEVICES=0 vllm serve /home/modern/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B   </span></span>
<span class="line"><span>--port=8102   </span></span>
<span class="line"><span>--max-model-len=1024</span></span>
<span class="line"><span>--max-model-len=2048</span></span>
<span class="line"><span>#较大的max-model-len可以处理更长的上下文，但也会增加显存的占用。</span></span>
<span class="line"><span>#需要处理的上下文长度：如果必须处理长达32k tokens的文本，那么第一个命令的max-model-len是必须的，但需要确保显存足够,</span></span>
<span class="line"><span>#max-model-len是2048，这在大多数情况下可能已经足够，尤其是对于一般的对话或文本生成任务。适合对话、摘要等常规任务（上下文≤2k</span></span>
<span class="line"><span>--disable-log-stats</span></span>
<span class="line"><span>--gpu-memory-utilization=0.9 </span></span>
<span class="line"><span>#--gpu-memory-utilization=0.9，这意味着允许vLLM使用90%的GPU显存。</span></span>
<span class="line"><span>#gpu-memory-utilization，可以更精细地控制显存使用，避免OOM崩溃。</span></span>
<span class="line"><span>--trust-remote-code</span></span>
<span class="line"><span>      </span></span>
<span class="line"><span>--dtype=half    </span></span>
<span class="line"><span>--max-num-seqs=4</span></span>
<span class="line"><span>--max-num-seqs=8 \            # 减少并发序列数（默认64）</span></span>
<span class="line"><span>--disable-log-stats \          # 关闭统计日志以节省内存</span></span>
<span class="line"><span>--enforce-eager \            </span></span>
<span class="line"><span>#--enforce-eager    # 禁用CUDA Graph优化，这会让PyTorch使用eager模式而不是更优化的cuda graph</span></span>
<span class="line"><span>--block-size=16               # 减小内存块分配粒度</span></span>
<span class="line"><span></span></span>
<span class="line"><span>--block-size 16 \  # 提高KV缓存利用率（对长文本有效）</span></span>
<span class="line"><span>--swap-space 8 \    # 启用CPU卸载，极端情况下扩展上下文 </span></span>
<span class="line"><span></span></span>
<span class="line"><span>#CUDA_VISIBLE_DEVICES=0指定只使用第0号GPU，也就是单卡运行</span></span>
<span class="line"><span>#命令指定了端口8102，而第一个没有指定，可能使用默认端口（通常是8000）。</span></span>
<span class="line"><span>#比如，7B模型，假设每个参数用2字节（比如半精度），参数量7B，那么模型本身占用的显存大约是7*10^9 * 2 bytes = 14 GB。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>  </span></span>
<span class="line"><span>CUDA_VISIBLE_DEVICES=0 vllm serve \</span></span>
<span class="line"><span>  --model $MODEL_DIR/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B \</span></span>
<span class="line"><span>  --port 8102 \</span></span>
<span class="line"><span>  --max-model-len 4096 \</span></span>
<span class="line"><span>  --gpu-memory-utilization 0.9  # 显存利用率（0.9表示90%）</span></span></code></pre></div><p><strong>参数调整建议</strong></p><ul><li><strong>显存不足</strong>：添加 <code>--quantization awq</code>（需模型支持AWQ量化）</li><li><strong>长文本生成</strong>：增大 <code>--max-model-len</code>（但可能需更多显存）</li><li><strong>多GPU支持</strong>：设置 <code>CUDA_VISIBLE_DEVICES=0,1</code>（多卡并行）</li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>python3 -m vllm.entrypoints.openai.api_server --model /input0/Qwen-1_8B-Chat/ --host 0.0.0.0 --port 8080 --dtype auto --max-num-seqs 32 --max-model-len 4096 --tensor-parallel-size 1 --trust-remote-code</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># 转换模型为GGUF格式</span></span>
<span class="line"><span>python3 convert.py /home/modern/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B</span></span>
<span class="line"><span>./quantize /home/modern/models/deepseek-aigguf/gguf-model Q4_K_M</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 启动推理</span></span>
<span class="line"><span>./main -m //home/modern/models/deepseek-aigguf/gguf-model-q4_k_m.gguf -n 256 --gpu-layers 40</span></span></code></pre></div><h3 id="_1-环境清理与准备" tabindex="-1"><strong>1. 环境清理与准备</strong> <a class="header-anchor" href="#_1-环境清理与准备" aria-label="Permalink to &quot;**1. 环境清理与准备**&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># 创建纯净虚拟环境（避免旧依赖干扰）</span></span>
<span class="line"><span>python -m venv vllm_env</span></span></code></pre></div><p><strong>1. 确认虚拟环境激活</strong></p><p>你正在使用名为 <code>vllm_env</code> 的虚拟环境。请先确保已激活该环境：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>source vllm_env/bin/activate  # Linux/Mac激活虚拟环境</span></span></code></pre></div><h3 id="‌2-安装指定版本的核心依赖" tabindex="-1">‌<strong>2. 安装指定版本的核心依赖</strong> <a class="header-anchor" href="#‌2-安装指定版本的核心依赖" aria-label="Permalink to &quot;‌**2. 安装指定版本的核心依赖**&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># 安装基础兼容版本（关键冲突解决）</span></span>
<span class="line"><span>pip install numpy==1.26.4 </span></span>
<span class="line"><span>pip install  numba==0.58.1 </span></span>
<span class="line"><span>pip install  fsspec==2024.12.0 </span></span>
<span class="line"><span>pip install  transformers==4.47.1 </span></span>
<span class="line"><span>pip install  torch==2.1.2  # 确保CUDA兼容性‌:ml-citation{ref=&quot;1,6&quot; data=&quot;citationList&quot;}</span></span></code></pre></div><h3 id="‌3-安装vllm及关联库" tabindex="-1">‌<strong>3. 安装vLLM及关联库</strong> <a class="header-anchor" href="#‌3-安装vllm及关联库" aria-label="Permalink to &quot;‌**3. 安装vLLM及关联库**&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># 安装vLLM 0.8.2（需与numpy&lt;2.0兼容）</span></span>
<span class="line"><span>pip install vllm==0.8.2</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 如果使用 AWQ 量化模型，需额外安装 autoawq（非必须，但 Qwen2.5-Coder-7B-Instruct-AWQ 需要）</span></span>
<span class="line"><span># 修复AutoAWQ冲突</span></span>
<span class="line"><span>pip install autoawq==0.2.8</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span># 安装datasets 3.4.1（需匹配fsspec）</span></span>
<span class="line"><span>pip install datasets==3.4.1</span></span></code></pre></div><h3 id="_4-验证安装结果" tabindex="-1"><strong>4. 验证安装结果</strong> <a class="header-anchor" href="#_4-验证安装结果" aria-label="Permalink to &quot;**4. 验证安装结果**&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># 检查关键库版本</span></span>
<span class="line"><span>pip show numpy numba transformers fsspec autoawq vllm</span></span>
<span class="line"><span>pip show datasets</span></span>
<span class="line"><span>pip show vllm</span></span></code></pre></div><p>预期输出</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>numpy==1.26.4</span></span>
<span class="line"><span>numba==0.58.1</span></span>
<span class="line"><span>transformers==4.47.1</span></span>
<span class="line"><span>fsspec==2024.12.0</span></span>
<span class="line"><span>autoawq==0.2.8</span></span>
<span class="line"><span>vllm==0.8.2</span></span></code></pre></div><h3 id="‌5-加速安装技巧" tabindex="-1">‌<strong>5. 加速安装技巧</strong> <a class="header-anchor" href="#‌5-加速安装技巧" aria-label="Permalink to &quot;‌**5. 加速安装技巧**&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># 使用阿里云镜像加速</span></span>
<span class="line"><span>pip install -i https://mirrors.aliyun.com/pypi/simple/ [包名]</span></span>
<span class="line"><span>#清华源</span></span>
<span class="line"><span>pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</span></span></code></pre></div><h3 id="关键依赖关系表‌" tabindex="-1"><strong>关键依赖关系表</strong>‌ <a class="header-anchor" href="#关键依赖关系表‌" aria-label="Permalink to &quot;**关键依赖关系表**‌&quot;">​</a></h3><table tabindex="0"><thead><tr><th>库名称</th><th>要求版本</th><th>冲突原因</th><th>解决方案</th></tr></thead><tbody><tr><td>numpy</td><td>1.26.4</td><td>vllm/numba不兼容numpy≥2.0‌1</td><td>强制降级</td></tr><tr><td>numba</td><td>0.58.1</td><td>兼容numpy 1.26.x‌16</td><td>固定版本</td></tr><tr><td>transformers</td><td>4.47.1</td><td>autoawq版本限制‌12</td><td>降级至兼容范围</td></tr><tr><td>fsspec</td><td>2024.12.0</td><td>datasets版本限制‌13</td><td>安装旧版</td></tr></tbody></table><h3 id="_2-安装-vllm‌" tabindex="-1"><strong>2. 安装 vLLM</strong>‌ <a class="header-anchor" href="#_2-安装-vllm‌" aria-label="Permalink to &quot;**2. 安装 vLLM**‌&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>pip list | grep vllm</span></span>
<span class="line"><span># 输出应包含类似：vllm 0.4.0</span></span>
<span class="line"><span>#vllm                              0.8.2</span></span></code></pre></div><h3 id="_3-检查-cuda-和-pytorch-兼容性‌" tabindex="-1"><strong>3. 检查 CUDA 和 PyTorch 兼容性</strong>‌ <a class="header-anchor" href="#_3-检查-cuda-和-pytorch-兼容性‌" aria-label="Permalink to &quot;**3. 检查 CUDA 和 PyTorch 兼容性**‌&quot;">​</a></h3><p>vLLM 需要 CUDA 和 PyTorch 支持。确保以下依赖已安装：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>#验证命令</span></span>
<span class="line"><span>nvcc --version</span></span>
<span class="line"><span># 检查 PyTorch 版本</span></span>
<span class="line"><span>python -c &quot;import torch; print(torch.__version__)&quot;</span></span>
<span class="line"><span># 检查 python 版本</span></span>
<span class="line"><span>python --version</span></span>
<span class="line"><span># 检查 PyTorch 是否支持 CUDA</span></span>
<span class="line"><span>python -c &quot;import torch; print(torch.cuda.is_available())&quot;</span></span>
<span class="line"><span># 输出应为：True</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 检查 CUDA 版本（需要 &gt;= 11.8）</span></span>
<span class="line"><span>nvidia-smi | grep &quot;CUDA Version&quot;</span></span>
<span class="line"><span>#| NVIDIA-SMI 530.30.02              Driver Version: 531.14       CUDA Version: 12.1     |</span></span></code></pre></div><h3 id="步骤-6-测试api调用" tabindex="-1"><strong>步骤 6：测试API调用</strong> <a class="header-anchor" href="#步骤-6-测试api调用" aria-label="Permalink to &quot;**步骤 6：测试API调用**&quot;">​</a></h3><h4 id="通过python代码调用" tabindex="-1">通过Python代码调用 <a class="header-anchor" href="#通过python代码调用" aria-label="Permalink to &quot;通过Python代码调用&quot;">​</a></h4><p>检查本地目录是否包含以下关键文件：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>your_project_folder/</span></span>
<span class="line"><span>├── models/</span></span>
<span class="line"><span>│   └── Qwen/</span></span>
<span class="line"><span>│       └── Qwen2.5-Coder-7B-Instruct-AWQ/  # 重命名目录</span></span>
<span class="line"><span>│           ├── config.json</span></span>
<span class="line"><span>│           ├── tokenizer_config.json</span></span>
<span class="line"><span>│           ├── model.safetensors          # 合并后的单文件</span></span>
<span class="line"><span>│           └── tokenizer.json</span></span>
<span class="line"><span>├── scripts/                              # 新建脚本目录</span></span>
<span class="line"><span>│   └── qwen_inference.py</span></span>
<span class="line"><span>└── vllm_env/                            # 仅存放虚拟环境</span></span></code></pre></div><p>然后，您可以利用 <a href="https://platform.openai.com/docs/api-reference/chat/completions/create" target="_blank" rel="noreferrer">create chat interface</a> 来与Qwen进行对话：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from openai import OpenAI</span></span>
<span class="line"><span># Set OpenAI&#39;s API key and API base to use vLLM&#39;s API server.</span></span>
<span class="line"><span>openai_api_key = &quot;EMPTY&quot;</span></span>
<span class="line"><span>openai_api_base = &quot;http://localhost:8000/v1&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>client = OpenAI(</span></span>
<span class="line"><span>    api_key=openai_api_key,</span></span>
<span class="line"><span>    base_url=openai_api_base,</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>chat_response = client.chat.completions.create(</span></span>
<span class="line"><span>    model=&quot;Qwen/Qwen2.5-7B-Instruct&quot;,</span></span>
<span class="line"><span>    messages=[</span></span>
<span class="line"><span>        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are Qwen, created by Alibaba Cloud. You are a helpful assistant.&quot;},</span></span>
<span class="line"><span>        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell me something about large language models.&quot;},</span></span>
<span class="line"><span>    ],</span></span>
<span class="line"><span>    temperature=0.7,</span></span>
<span class="line"><span>    top_p=0.8,</span></span>
<span class="line"><span>    max_tokens=512,</span></span>
<span class="line"><span>    extra_body={</span></span>
<span class="line"><span>        &quot;repetition_penalty&quot;: 1.05,</span></span>
<span class="line"><span>    },</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span>print(&quot;Chat response:&quot;, chat_response)</span></span></code></pre></div><h2 id="上下文支持扩展" tabindex="-1">上下文支持扩展 <a class="header-anchor" href="#上下文支持扩展" aria-label="Permalink to &quot;上下文支持扩展&quot;">​</a></h2><p>Qwen2.5 模型的上下文长度默认设置为 3 2768 个token。为了处理超出 3 2768 个token的大量输入，我们使用了 <a href="https://arxiv.org/abs/2309.00071" target="_blank" rel="noreferrer">YaRN</a>，这是一种增强模型长度外推的技术，确保在处理长文本时的最优性能。</p><p>vLLM 支持 YaRN，并且可以通过在模型的 <code>config.json</code> 文件中添加一个 <code>rope_scaling</code> 字段来启用它。例如，</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>{</span></span>
<span class="line"><span>  ...,</span></span>
<span class="line"><span>  &quot;rope_scaling&quot;: {</span></span>
<span class="line"><span>    &quot;factor&quot;: 4.0,</span></span>
<span class="line"><span>    &quot;original_max_position_embeddings&quot;: 32768,</span></span>
<span class="line"><span>    &quot;type&quot;: &quot;yarn&quot;</span></span>
<span class="line"><span>  }</span></span>
<span class="line"><span>}</span></span></code></pre></div><p><strong>激活虚拟环境</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>source vllm_env/bin/activate</span></span></code></pre></div><p><strong>运行脚本</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>cd scripts</span></span>
<span class="line"><span>python qwen_inference.py</span></span>
<span class="line"><span>python chat.py</span></span></code></pre></div><p>问题1:</p><p>prompts = [&quot;Write a Python function to calculate factorial:&quot;] outputs = llm.generate(prompts, sampling_params)</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>```python</span></span>
<span class="line"><span>def factorial(n):</span></span>
<span class="line"><span>    # Base case: factorial of 0 is 1</span></span>
<span class="line"><span>    if n == 0:</span></span>
<span class="line"><span>        return 1</span></span>
<span class="line"><span>    # Initialize result to 1</span></span>
<span class="line"><span>    result = 1</span></span>
<span class="line"><span>    # Loop through numbers from 1 to n</span></span>
<span class="line"><span>    for i in range(1, n + 1):</span></span>
<span class="line"><span>        result *= i  # Multiply result by current number i</span></span>
<span class="line"><span>    return result</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Test the function</span></span>
<span class="line"><span>print(factorial(5))  # Output: 120</span></span>
<span class="line"><span>print(factorial(0))  # Output: 1</span></span>
<span class="line"><span>print(factorial(3))  # Output: 6</span></span>
<span class="line"><span>```</span></span></code></pre></div><p>在WSL或Windows中创建 <code>test_api.py</code>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>prompt=&quot;如何学习人工智能？&quot;,</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化客户端（注意端口与启动服务时一致）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">client </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    base_url</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;http://localhost:8102/v1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 本地服务地址</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    api_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;EMPTY&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # vLLM无需认证</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 生成文本</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> client.completions.create(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-14B&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    prompt</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;如何高效学习深度学习？&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    max_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">200</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,    </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 生成的最大token数</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    temperature</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.7</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,   </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 控制随机性（0-1，越大越随机）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    top_p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,         </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 核采样阈值（通常与temperature配合）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    stop</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]        </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 停止生成的条件（如遇到换行符则停止）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(response.choices[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].text)</span></span></code></pre></div><p><strong>运行测试</strong></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>pip install openai  # 确保已安装</span></span>
<span class="line"><span>python test_api.py</span></span></code></pre></div><h4 id="_2-2-通过curl命令测试" tabindex="-1">2.2 通过curl命令测试 <a class="header-anchor" href="#_2-2-通过curl命令测试" aria-label="Permalink to &quot;2.2 通过curl命令测试&quot;">​</a></h4><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">curl</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> http://localhost:8000/v1/completions</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  -H</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Content-Type: application/json&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">   -d</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;{  &quot;model&quot;:&quot;/home/modern/models/Qwen/Qwen2.5-Coder-7B-Instruct-AWQ&quot;,    &quot;prompt&quot;: &quot;中国的首都是哪里？&quot;,    &quot;max_tokens&quot;: 50  }&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Call the server using curl:</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">curl</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -X</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> POST</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;http://localhost:8000/v1/chat/completions&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">	-H</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Content-Type: application/json&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">	--data</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;{</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">		&quot;model&quot;:&quot;/home/modern/models/Qwen/Qwen2.5-Coder-7B-Instruct-AWQ&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">		&quot;messages&quot;: [</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">			{</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">				&quot;role&quot;: &quot;user&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">				&quot;content&quot;: &quot;What is the capital of France?&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">			}</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">		],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">		&quot;stream&quot;: true,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">		&quot;temperature&quot;: 0.1</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">		</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">	}&#39;</span></span></code></pre></div><h3 id="步骤-3-验证服务状态" tabindex="-1"><strong>步骤 3：验证服务状态</strong> <a class="header-anchor" href="#步骤-3-验证服务状态" aria-label="Permalink to &quot;**步骤 3：验证服务状态**&quot;">​</a></h3><h4 id="_3-1-检查服务日志" tabindex="-1">3.1 检查服务日志 <a class="header-anchor" href="#_3-1-检查服务日志" aria-label="Permalink to &quot;3.1 检查服务日志&quot;">​</a></h4><ul><li>服务启动后，终端会持续输出日志，观察是否有以下关键信息：</li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Uvicorn running on http://0.0.0.0:8102 (Press CTRL+C to quit)</span></span>
<span class="line"><span>NVIDIA CUDA initialized successfully  # 确认CUDA可用</span></span>
<span class="line"><span>Model loaded in 23.5s                  # 模型加载完成</span></span></code></pre></div><h4 id="_3-2-查看显存占用" tabindex="-1">3.2 查看显存占用 <a class="header-anchor" href="#_3-2-查看显存占用" aria-label="Permalink to &quot;3.2 查看显存占用&quot;">​</a></h4><p>在另一个WSL终端中运行：</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">watch</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -n</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> nvidia-smi</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # 每秒刷新显存占用情况</span></span></code></pre></div><p>正常情况：显存占用应接近 <code>--gpu-memory-utilization</code> 设置的比例（如90%）。</p><h3 id="步骤-4-高级用法" tabindex="-1"><strong>步骤 4：高级用法</strong> <a class="header-anchor" href="#步骤-4-高级用法" aria-label="Permalink to &quot;**步骤 4：高级用法**&quot;">​</a></h3><h4 id="_4-1-流式输出-streaming" tabindex="-1">4.1 流式输出（Streaming） <a class="header-anchor" href="#_4-1-流式输出-streaming" aria-label="Permalink to &quot;4.1 流式输出（Streaming）&quot;">​</a></h4><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>response = client.completions.create(</span></span>
<span class="line"><span>    model=&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-14B&quot;,</span></span>
<span class="line"><span>    prompt=&quot;请写一首关于春天的诗：&quot;,</span></span>
<span class="line"><span>    stream=True  # 启用流式输出</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>for chunk in response:</span></span>
<span class="line"><span>    print(chunk.choices[0].text, end=&quot;&quot;, flush=True)</span></span></code></pre></div><h4 id="_4-2-批量推理" tabindex="-1">4.2 批量推理 <a class="header-anchor" href="#_4-2-批量推理" aria-label="Permalink to &quot;4.2 批量推理&quot;">​</a></h4><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>batch_prompts = [</span></span>
<span class="line"><span>    &quot;深度学习的三大基础概念是：&quot;,</span></span>
<span class="line"><span>    &quot;如何预防感冒？&quot;,</span></span>
<span class="line"><span>    &quot;Python的GIL是什么？&quot;</span></span>
<span class="line"><span>]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>for prompt in batch_prompts:</span></span>
<span class="line"><span>    response = client.completions.create(</span></span>
<span class="line"><span>        model=&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-14B&quot;,</span></span>
<span class="line"><span>        prompt=prompt,</span></span>
<span class="line"><span>        max_tokens=100</span></span>
<span class="line"><span>    )</span></span>
<span class="line"><span>    print(f&quot;问题：{prompt}\n回答：{response.choices[0].text}\n&quot;)</span></span></code></pre></div><h3 id="常见问题解决" tabindex="-1"><strong>常见问题解决</strong> <a class="header-anchor" href="#常见问题解决" aria-label="Permalink to &quot;**常见问题解决**&quot;">​</a></h3><ol><li><p><strong>CUDA不可用</strong></p><ul><li>检查NVIDIA驱动版本：<code>nvidia-smi</code>（在WSL中应能识别GPU）</li><li>确保CUDA路径正确：<code>echo $PATH | grep cuda</code></li></ul></li><li><p><strong>模型加载失败</strong></p><ul><li>检查模型路径权限：<code>chmod -R 755 $MODEL_DIR</code></li><li>确认模型文件完整（下载中断时重新运行<code>modelscope download</code>）</li><li>检查模型路径是否正确（区分大小写）</li><li>确保模型文件完整（对比Hugging Face仓库的文件列表）</li></ul></li><li><p><strong>显存不足</strong></p><ul><li>降低<code>--max-model-len</code>（如2048）</li><li>关闭其他占用GPU的程序（如Windows游戏、录屏软件）</li></ul><p><strong>API调用超时</strong></p><ul><li>增加 <code>--max-num-seqs 32</code>（服务启动参数，提高并发处理能力）</li><li>减少 <code>max_tokens</code> 值</li></ul><p><strong>生成内容质量差</strong></p><ul><li>调整 <code>temperature</code>（降低值使输出更确定性）</li><li>设置 <code>top_k=50</code> 或 <code>top_p=0.9</code> 限制采样范围</li></ul></li></ol><h3 id="性能优化建议" tabindex="-1"><strong>性能优化建议</strong> <a class="header-anchor" href="#性能优化建议" aria-label="Permalink to &quot;**性能优化建议**&quot;">​</a></h3><ol><li><p><strong>启用连续批处理</strong> 添加 <code>--enforce-eager</code> 到启动参数（减少显存碎片）</p></li><li><p><strong>持久化服务</strong> 使用 <code>tmux</code> 或 <code>systemd</code> 保持服务后台运行：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>tmux new -s vllm</span></span>
<span class="line"><span># 启动服务后按 Ctrl+B, 再按 D 退出会话</span></span>
<span class="line"><span># 重新连接：tmux attach -t vllm</span></span></code></pre></div></li><li><p><strong>模型量化</strong> 如果使用AWQ量化版模型（需重新下载）：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>vllm serve --model path/to/model --quantization awq</span></span></code></pre></div></li></ol><h3 id="优化建议" tabindex="-1"><strong>优化建议</strong> <a class="header-anchor" href="#优化建议" aria-label="Permalink to &quot;**优化建议**&quot;">​</a></h3><ul><li>将模型存储在WSL的ext4分区（默认路径如<code>/home/</code>），避免挂载Windows NTFS目录（I/O性能差）。</li><li>使用<code>tmux</code>或<code>screen</code>保持服务后台运行：</li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>sudo apt install tmux</span></span>
<span class="line"><span>tmux new -s vllm</span></span>
<span class="line"><span># 启动服务后按Ctrl+B, 再按D退出会话，需恢复时运行 tmux attach -t vllm</span></span></code></pre></div><p>完成上述步骤后，你的 DeepSeek-R1 14B 模型即可通过 API 提供服务。建议先从简单问题测试，逐步调整参数以适应实际需求。</p></div></div></main><footer class="VPDocFooter" data-v-4b99b89c data-v-30ab9f1f><!--[--><!--]--><div class="edit-info" data-v-30ab9f1f><!----><div class="last-updated" data-v-30ab9f1f><p class="VPLastUpdated" data-v-30ab9f1f data-v-f6a70a25>Last Updated: <time datetime="2025-04-12T08:57:15.000Z" data-v-f6a70a25></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-30ab9f1f><span class="visually-hidden" id="doc-footer-aria-label" data-v-30ab9f1f>Pager</span><div class="pager" data-v-30ab9f1f><!----></div><div class="pager" data-v-30ab9f1f><a class="VPLink link pager-link next" href="/docs/ollama/Ollama.html" data-v-30ab9f1f><!--[--><span class="desc" data-v-30ab9f1f>Next page</span><span class="title" data-v-30ab9f1f>Ollama</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-96fd1f2d data-v-ab84e9ce><div class="container" data-v-ab84e9ce><p class="message" data-v-ab84e9ce>Released under the MIT License.</p><p class="copyright" data-v-ab84e9ce>Copyright © modern</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"backend_java.md\":\"DlTUUlxB\",\"backend_spring.md\":\"BBjINip7\",\"blogs_coding-001.md\":\"CwMpvUh0\",\"blogs_food-001.md\":\"g1Rl2GV8\",\"blogs_garden-001.md\":\"DD7eOoCX\",\"blogs_health-001.md\":\"C-8Yizbg\",\"blogs_life-001.md\":\"fpQu6CC2\",\"blogs_movie-001.md\":\"BFXhHmUN\",\"blogs_movie所有需要的字段.md\":\"DsDYPwNI\",\"blogs_music-001.md\":\"BZezbejh\",\"blogs_photo-001.md\":\"BziavrUh\",\"blogs_reading-001.md\":\"DcaaZqDR\",\"blogs_readme.md\":\"FAah44Sp\",\"blogs_travel-001.md\":\"CqCoahhs\",\"blogs_搭建一个在线电影网站python_flask.md\":\"ToCuosVQ\",\"cae_21讲二次开发大纲.md\":\"CikNfEUm\",\"cae_22讲set puts expr for循环.md\":\"BArCvlho\",\"cae_23讲列表和字符串的操作方法.md\":\"CqiB3mj0\",\"cae_24讲文件对话框的操作方法.md\":\"B-5wf8a1\",\"cae_contact与tie的主要区别.md\":\"DhX5QNSa\",\"cae_pc材质提手受拉失效分析.md\":\"DfbisDzb\",\"cae_pc材质提手的拉力失效分析.md\":\"BtGCRxQE\",\"cae_电池包翻转分析概述.md\":\"DzbTA-uU\",\"cae_第二十三讲 列表和字符串的操作方法 - 副本 (4).md\":\"BgATHHDl\",\"cae_第二十三讲 列表和字符串的操作方法 - 副本 (5).md\":\"DbhpSvj8\",\"cae_第二十三讲 列表和字符串的操作方法 - 副本 (6).md\":\"BRd6zGAU\",\"cae_第二十三讲 列表和字符串的操作方法.md\":\"DIo3Lof6\",\"contact.md\":\"B5yxjC-D\",\"frontend_ajax_day01_ajax入门.md\":\"BFaJcsbH\",\"frontend_ajax_day02_ajax综合案例.md\":\"BSMzZ2R2\",\"frontend_else_2024年前端学习路线图.md\":\"DfKUKltp\",\"frontend_else_else.md\":\"B8As1_pZ\",\"frontend_html_css_html_css.md\":\"jTJA2C3q\",\"frontend_javascript_javascript基础.md\":\"CucR-kjA\",\"frontend_javascript_javascript特效.md\":\"0X6yJ6n7\",\"frontend_javascript_javascript高级.md\":\"DmB7qkmB\",\"frontend_javascript_jquery基础使用.md\":\"BvdTHVBQ\",\"frontend_node.js_01初识node.js与内置模块.md\":\"BDX7-q6D\",\"frontend_node.js_02_模块化.md\":\"B9OdQO6y\",\"frontend_node.js_03_express.md\":\"B_-c3JQt\",\"frontend_node.js_04_数据库与身份认证.md\":\"B3mDjgBM\",\"frontend_node.js_05_ev_api_server.md\":\"DEhtN_X8\",\"frontend_node.js_06_ev_api_server.md\":\"CZkMKrwr\",\"frontend_node.js_ajax.md\":\"DhaPKz43\",\"frontend_node.js_day1.md\":\"l_5Pn8pD\",\"frontend_node.js_webpack.md\":\"w55FG97y\",\"frontend_vue_vue.md\":\"DTnVSN7P\",\"index.md\":\"BnCQZlXa\",\"notes_ajax入门.md\":\"DxemJlyG\",\"notes_b站缓存m4s.md\":\"VZaxzkd5\",\"notes_b站缓存m4s批量重命名.md\":\"B1VIX9FY\",\"notes_ffmpeg项目.md\":\"D5JLhbg4\",\"notes_github上删除项目中的个别文件.md\":\"j-AnVulJ\",\"notes_git常用命令.md\":\"Bz_T6nQF\",\"notes_pandoc命令.md\":\"DsVPhSku\",\"notes_下载和安装pandoc_windows版本.md\":\"BV5UJCl3\",\"notes_安装git.md\":\"6vbCdald\",\"notes_常用markdown语法.md\":\"CRSHxJXF\",\"notes_箭头函数.md\":\"uxd0kU4U\",\"ollama_cherry studio知识库.md\":\"myA-nRh4\",\"ollama_internlm2书生浦语.md\":\"ChCtxuIh\",\"ollama_javascript浏览器api.md\":\"BFzeyCgG\",\"ollama_javascript浏览器api_2.md\":\"vGbn2dZY\",\"ollama_llama 3.1 综合指南.md\":\"2Rkx8N7M\",\"ollama_ollama.md\":\"KES1ET6t\",\"ollama_prompt提示词优化原则.md\":\"zkh8oXKe\",\"ollama_vllm_ai答案.md\":\"D2Q3Dpps\",\"ollama_vllm_api_server.md\":\"DOIeAteq\",\"ollama_vllm_openai api格式详解.md\":\"5_j57dQH\",\"ollama_vllm_qwen2.5-coder能力.md\":\"D55ZuiOj\",\"ollama_vllm_ubuntu 22.04 lts2.md\":\"D4tQ1ST1\",\"ollama_vllm_ubuntu qwen2.5api.md\":\"C4LWIATo\",\"ollama_vllm_ubuntu qwen2.5api批量请求.md\":\"DJIEGDwY\",\"ollama_vllm_ubuntu qwen2.5api非流式调用.md\":\"C0W4W21t\",\"ollama_vllm_启用流式响应.md\":\"Bqmlwlwn\",\"ollama_从零到一，深入浅出大语言模型的奇妙世界.md\":\"QAjP19Fh\",\"vitepress_api-examples.md\":\"CEro5dA-\",\"vitepress_markdown-examples.md\":\"P3tuKidy\",\"vitepress_zh_guide_asset-handling.md\":\"wVKSP8Kj\",\"vitepress_zh_guide_cms.md\":\"DzKBVTrV\",\"vitepress_zh_guide_custom-theme.md\":\"CxSqJi9A\",\"vitepress_zh_guide_data-loading.md\":\"0QBZf9TH\",\"vitepress_zh_guide_deploy.md\":\"BtGPb6jP\",\"vitepress_zh_guide_extending-default-theme.md\":\"DJiwZCeP\",\"vitepress_zh_guide_frontmatter.md\":\"DswFoFkQ\",\"vitepress_zh_guide_getting-started.md\":\"D9hNARpo\",\"vitepress_zh_guide_i18n.md\":\"2cxdqpbP\",\"vitepress_zh_guide_markdown.md\":\"DKdRIjOM\",\"vitepress_zh_guide_migration-from-vitepress-0.md\":\"Dsp2LcXh\",\"vitepress_zh_guide_migration-from-vuepress.md\":\"QLsCsrBf\",\"vitepress_zh_guide_mpa-mode.md\":\"Me1XdH2l\",\"vitepress_zh_guide_routing.md\":\"CZkRXGcf\",\"vitepress_zh_guide_sitemap-generation.md\":\"D0orRdGp\",\"vitepress_zh_guide_ssr-compat.md\":\"BFY5sur4\",\"vitepress_zh_guide_using-vue.md\":\"Ck4qqKzm\",\"vitepress_zh_guide_what-is-vitepress.md\":\"n1dzIQez\",\"vitepress_zh_index.md\":\"C0yNupvx\",\"vitepress_zh_reference_cli.md\":\"Bh_rdDXe\",\"vitepress_zh_reference_default-theme-badge.md\":\"w13a6FZl\",\"vitepress_zh_reference_default-theme-carbon-ads.md\":\"BsSB5fUQ\",\"vitepress_zh_reference_default-theme-config.md\":\"Bhjs7zod\",\"vitepress_zh_reference_default-theme-edit-link.md\":\"Bxb_GPfW\",\"vitepress_zh_reference_default-theme-footer.md\":\"CCbQG4Lm\",\"vitepress_zh_reference_default-theme-home-page.md\":\"5-rGEi-t\",\"vitepress_zh_reference_default-theme-last-updated.md\":\"BIPOAr1U\",\"vitepress_zh_reference_default-theme-layout.md\":\"CIz0q721\",\"vitepress_zh_reference_default-theme-nav.md\":\"CQL-NhT5\",\"vitepress_zh_reference_default-theme-prev-next-links.md\":\"DN7rO8T0\",\"vitepress_zh_reference_default-theme-search.md\":\"CLNmKzM9\",\"vitepress_zh_reference_default-theme-sidebar.md\":\"D_vkBnRV\",\"vitepress_zh_reference_default-theme-team-page.md\":\"Jsc5bj-W\",\"vitepress_zh_reference_frontmatter-config.md\":\"DCi6oN7E\",\"vitepress_zh_reference_runtime-api.md\":\"BwVvfCXj\",\"vitepress_zh_reference_site-config.md\":\"BJJOBpfB\",\"vitepress_部署_dist部署.md\":\"DzGIVUth\",\"vitepress_部署_narbar单独抽离成文件.md\":\"D75tSTTT\",\"vitepress_部署_sidebar单独抽离成文件.md\":\"B4nGudve\",\"vitepress_部署_vitepress_github pages详细v1.6.3.md\":\"DZ9xxqhF\",\"vitepress_部署_vitepress从0到1.md\":\"Dp8C-MKx\",\"vitepress_部署_vitepress部署.md\":\"DX1JVILX\",\"vitepress_部署_vitepress部署v1.6.3.md\":\"Cifh3BAE\",\"vitepress_部署_基于目录为vitepress生成侧边栏.md\":\"BDXwT92t\",\"vitepress_部署_支持pc和wap自适应.md\":\"BOobsDgI\",\"vuepress_a_node.js安装.md\":\"DqK-fFR3\",\"vuepress_b_npm镜像站.md\":\"DNli_yka\",\"vuepress_c_vuepress@1.9.10.md\":\"Brveb-lD\",\"vuepress_什么是敏感信息.md\":\"DSpbO79Q\",\"vuepress_复现vuepress.md\":\"BpMMZPk3\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"modern的Vitepress文档\",\"description\":\"一个vitepress站点\",\"base\":\"/docs/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"outlineTitle\":\"文章目录\",\"outline\":[2,6],\"logo\":\"/comet.png\",\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"CAE\",\"items\":[{\"text\":\"PC材质提手受拉失效分析\",\"link\":\"/CAE/PC材质提手受拉失效分析\"},{\"text\":\"PC材质提手的拉力失效分析\",\"link\":\"/CAE/PC材质提手的拉力失效分析\"},{\"text\":\"21讲二次开发大纲\",\"link\":\"/CAE/21讲二次开发大纲\"},{\"text\":\"22讲 set puts expr for循环\",\"link\":\"/CAE/22讲set puts expr for循环\"},{\"text\":\"23讲列表和字符串的操作方法\",\"link\":\"/CAE/23讲列表和字符串的操作方法\"},{\"text\":\"24讲文件对话框的操作方法\",\"link\":\"/CAE/24讲文件对话框的操作方法\"}]},{\"text\":\"ollama\",\"items\":[{\"text\":\"Cherry Studio知识库\",\"link\":\"/ollama/Cherry Studio知识库\"}]},{\"text\":\"VitePress\",\"items\":[{\"text\":\"VitePress\",\"link\":\"/vitepress/zh/guide/what-is-vitepress\"},{\"text\":\"参考\",\"link\":\"/vitepress/zh/reference/site-config\"},{\"text\":\"哈哈\",\"link\":\"/vitepress/haha\"},{\"text\":\"vitepress\",\"items\":[{\"text\":\"VitePress+Github Pages详细v1.6.3\",\"link\":\"/vitepress/部署/VitePress+Github Pages详细v1.6.3\"},{\"text\":\"VitePress部署v1.6.3\",\"link\":\"/vitepress/部署/VitePress部署v1.6.3\"},{\"text\":\"sidebar单独抽离成文件\",\"link\":\"/vitepress/部署/sidebar单独抽离成文件\"}]},{\"text\":\"vitepress\",\"items\":[{\"text\":\"A_Node.js安装\",\"link\":\"/vuepress/A_Node.js安装.md\"},{\"text\":\"B_npm镜像站\",\"link\":\"/vuepress/B_npm镜像站\"},{\"text\":\"C_vuepress@1.9.10\",\"link\":\" /vuepress/C_vuepress@1.9.10\"}]},{\"text\":\"Examples\",\"link\":\"/vitepress/markdown-examples\"},{\"text\":\"api-examples\",\"link\":\"/vitepress/api-examples\"}]},{\"text\":\"笔记\",\"items\":[{\"text\":\"git常用命令\",\"link\":\"/notes/git常用命令.md\"},{\"text\":\"常用Markdown\",\"link\":\"/notes/常用Markdown语法\"},{\"text\":\"下载和安装Pandoc_Windows版本\",\"link\":\"/notes/下载和安装Pandoc_Windows版本\"},{\"text\":\"GitHub\",\"link\":\"/notes/GitHub上删除项目中的个别文件\"},{\"text\":\"安装git\",\"link\":\"/notes/安装git\"},{\"text\":\"note\",\"link\":\"/notes/note\"},{\"text\":\"Pandoc命令\",\"link\":\"/notes/Pandoc命令\"}]},{\"text\":\"前端\",\"items\":[{\"text\":\"Day01_AJAX入门\",\"link\":\"/frontEnd/ajax/Day01_AJAX入门.md\"},{\"text\":\"vue\",\"link\":\"/frontEnd/vue/vue\"},{\"text\":\"JavaScript\",\"link\":\"/frontEnd/JavaScript/JavaScript\"},{\"text\":\"01初识Node.js与内置模块\",\"link\":\"/frontEnd/Node.js/01初识Node.js与内置模块.md\"},{\"text\":\"02_模块化\",\"link\":\"/frontEnd/Node.js/02_模块化\"},{\"text\":\"03_Express\",\"link\":\"/frontEnd/Node.js/03_Express\"},{\"text\":\"04_数据库与身份认证\",\"link\":\"/frontEnd/Node.js/04_数据库与身份认证\"},{\"text\":\"05_ev_api_server\",\"link\":\"/frontEnd/Node.js/05_ev_api_server\"},{\"text\":\"06_ev_api_server\",\"link\":\"/frontEnd/Node.js/06_ev_api_server\"},{\"text\":\"2024年前端学习路线图\",\"link\":\"/frontEnd/else/2024年前端学习路线图\"},{\"text\":\"else\",\"link\":\"/frontEnd/else/else.md\"}]},{\"text\":\"后端\",\"items\":[{\"text\":\"spring\",\"link\":\"/backEnd/spring\"},{\"text\":\"java\",\"link\":\"/backEnd/java\"}]},{\"text\":\"blogs\",\"items\":[{\"text\":\"编程日志\",\"link\":\"/blogs/coding-001\"},{\"text\":\"美食记录\",\"link\":\"/blogs/food-001/\"},{\"text\":\"园艺笔记\",\"link\":\"/blogs/garden-001/\"},{\"text\":\"健康生活\",\"link\":\"/blogs/health-001\"},{\"text\":\"生活随笔\",\"link\":\"/blogs/life-001\"},{\"text\":\"影视评论\",\"link\":\"/blogs/movie-001\"},{\"text\":\"音乐分享\",\"link\":\"/blogs/music-001\"},{\"text\":\"摄影作品\",\"link\":\"/blogs/photo-001\"},{\"text\":\"读书笔记\",\"link\":\"/blogs/reading-001\"},{\"text\":\"旅行日记\",\"link\":\"/blogs/travel-001\"}]}],\"sidebar\":{\"/backEnd/\":[{\"text\":\"spring\",\"link\":\"/backEnd/spring\"},{\"text\":\"java\",\"link\":\"/backEnd/java\"}],\"/frontEnd/\":[{\"text\":\"Day01_AJAX入门\",\"link\":\"/frontEnd/ajax/Day01_AJAX入门.md\"},{\"text\":\"Day02_AJAX的GET请求\",\"link\":\"/frontEnd/ajax/Day02_AJAX的GET请求.md\"},{\"text\":\"vue\",\"link\":\"/frontEnd/vue/vue\"},{\"text\":\"JavaScript\",\"link\":\"/frontEnd/JavaScript/JavaScript\"},{\"text\":\"2024年前端学习路线图\",\"link\":\"/frontEnd/else/2024年前端学习路线图.md\"},{\"text\":\"01初识Node.js与内置模块\",\"link\":\"/frontEnd/Node.js/01初识Node.js与内置模块.md\"},{\"text\":\"02_模块化\",\"link\":\"/frontEnd/Node.js/02_模块化\"},{\"text\":\"03_Express\",\"link\":\"/frontEnd/Node.js/03_Express\"},{\"text\":\"04_数据库与身份认证\",\"link\":\"/frontEnd/Node.js/04_数据库与身份认证\"},{\"text\":\"05_ev_api_server\",\"link\":\"/frontEnd/Node.js/05_ev_api_server\"},{\"text\":\"06_ev_api_server\",\"link\":\"/frontEnd/Node.js/06_ev_api_server\"},{\"text\":\"else\",\"link\":\"/frontEnd/else/else.md\"}],\"/CAE/\":[{\"text\":\"PC材质提手受拉失效分析\",\"link\":\"/CAE/PC材质提手受拉失效分析.md\"},{\"text\":\"PC材质提手的拉力失效分析\",\"link\":\"/CAE/PC材质提手的拉力失效分析.md\"},{\"text\":\"21讲二次开发大纲\",\"link\":\"/CAE/21讲二次开发大纲\"},{\"text\":\"22讲 set puts expr for循环\",\"link\":\"/CAE/22讲set puts expr for循环\"},{\"text\":\"23讲列表和字符串的操作方法\",\"link\":\"/CAE/23讲列表和字符串的操作方法\"},{\"text\":\"24讲文件对话框的操作方法\",\"link\":\"/CAE/24讲文件对话框的操作方法\"},{\"text\":\"22讲 set puts expr for循环\",\"link\":\"/CAE/22讲set puts expr for循环.md\"}],\"/blogs/\":[{\"text\":\"编程日志\",\"link\":\"/blogs/coding-001\"},{\"text\":\"美食记录\",\"link\":\"/blogs/food-001/\"},{\"text\":\"园艺笔记\",\"link\":\"/blogs/garden-001/\"},{\"text\":\"健康生活\",\"link\":\"/blogs/health-001\"},{\"text\":\"生活随笔\",\"link\":\"/blogs/life-001\"},{\"text\":\"影视评论\",\"link\":\"/blogs/movie-001\"},{\"text\":\"音乐分享\",\"link\":\"/blogs/music-001\"},{\"text\":\"摄影作品\",\"link\":\"/blogs/photo-001\"},{\"text\":\"读书笔记\",\"link\":\"/blogs/reading-001\"},{\"text\":\"旅行日记\",\"link\":\"/blogs/travel-001\"}],\"/notes/\":[{\"text\":\"git常用命令\",\"link\":\"/notes/git常用命令\"},{\"text\":\"GitHub\",\"link\":\"/notes/GitHub上删除项目中的个别文件\"},{\"text\":\"常用Markdown\",\"link\":\"/notes/常用Markdown语法\"},{\"text\":\"下载和安装Pandoc_Windows版本\",\"link\":\"/notes/下载和安装Pandoc_Windows版本\"},{\"text\":\"安装git\",\"link\":\"/notes/安装git\"},{\"text\":\"note\",\"link\":\"/notes/note\"},{\"text\":\"Pandoc命令\",\"link\":\"/notes/Pandoc命令\"},{\"text\":\"FFmpeg项目\",\"link\":\"/notes/FFmpeg项目\"},{\"text\":\"B站缓存m4s\",\"link\":\"/notes/B站缓存m4s\"},{\"text\":\"B站缓存m4s批量重命名\",\"link\":\"/notes/B站缓存m4s批量重命名\"},{\"text\":\"箭头函数\",\"link\":\"/notes/箭头函数\"}],\"/ollama/\":[{\"text\":\"Ollama\",\"link\":\"/ollama/Ollama\"},{\"text\":\"Cherry Studio知识库\",\"link\":\"/ollama/Cherry Studio知识库\"},{\"text\":\"InternLM2书生浦语\",\"link\":\"/ollama/InternLM2书生浦语\"},{\"text\":\"Llama 3.1 综合指南\",\"link\":\"/ollama/Llama 3.1 综合指南\"},{\"text\":\"从零到一，深入浅出大语言模型的奇妙世界\",\"link\":\"/ollama/从零到一，深入浅出大语言模型的奇妙世界\"},{\"text\":\"Prompt提示词优化原则\",\"link\":\"/ollama/Prompt提示词优化原则\"}],\"/vitepress/zh/guide/\":{\"base\":\"/vitepress/zh/guide/\",\"items\":[{\"text\":\"简介\",\"collapsed\":false,\"items\":[{\"text\":\"什么是 VitePress？\",\"link\":\"what-is-vitepress\"},{\"text\":\"快速开始\",\"link\":\"getting-started\"},{\"text\":\"路由\",\"link\":\"routing\"},{\"text\":\"部署\",\"link\":\"deploy\"}]},{\"text\":\"写作\",\"collapsed\":false,\"items\":[{\"text\":\"Markdown 扩展\",\"link\":\"markdown\"},{\"text\":\"资源处理\",\"link\":\"asset-handling\"},{\"text\":\"frontmatter\",\"link\":\"frontmatter\"},{\"text\":\"在 Markdown 使用 Vue\",\"link\":\"using-vue\"},{\"text\":\"国际化\",\"link\":\"i18n\"}]},{\"text\":\"自定义\",\"collapsed\":false,\"items\":[{\"text\":\"自定义主题\",\"link\":\"custom-theme\"},{\"text\":\"扩展默认主题\",\"link\":\"extending-default-theme\"},{\"text\":\"构建时数据加载\",\"link\":\"data-loading\"},{\"text\":\"SSR 兼容性\",\"link\":\"ssr-compat\"},{\"text\":\"连接 CMS\",\"link\":\"cms\"}]},{\"text\":\"实验性功能\",\"collapsed\":false,\"items\":[{\"text\":\"MPA 模式\",\"link\":\"mpa-mode\"},{\"text\":\"sitemap 生成\",\"link\":\"sitemap-generation\"}]},{\"text\":\"配置和 API 参考\",\"base\":\"/zh/reference/\",\"link\":\"site-config\"}]},\"/vitepress/zh/reference/\":{\"base\":\"/vitepress/zh/reference/\",\"items\":[{\"text\":\"参考\",\"items\":[{\"text\":\"站点配置\",\"link\":\"site-config\"},{\"text\":\"frontmatter 配置\",\"link\":\"frontmatter-config\"},{\"text\":\"运行时 API\",\"link\":\"runtime-api\"},{\"text\":\"CLI\",\"link\":\"cli\"},{\"text\":\"默认主题\",\"base\":\"/document/vitepress/zh/reference/default-theme-\",\"items\":[{\"text\":\"概览\",\"link\":\"config\"},{\"text\":\"导航栏\",\"link\":\"nav\"},{\"text\":\"侧边栏\",\"link\":\"sidebar\"},{\"text\":\"主页\",\"link\":\"home-page\"},{\"text\":\"页脚\",\"link\":\"footer\"},{\"text\":\"布局\",\"link\":\"layout\"},{\"text\":\"徽章\",\"link\":\"badge\"},{\"text\":\"团队页\",\"link\":\"team-page\"},{\"text\":\"上下页链接\",\"link\":\"prev-next-links\"},{\"text\":\"编辑链接\",\"link\":\"edit-link\"},{\"text\":\"最后更新时间戳\",\"link\":\"last-updated\"},{\"text\":\"搜索\",\"link\":\"search\"},{\"text\":\"Carbon Ads\",\"link\":\"carbon-ads\"}]}]}]},\"/vitepress/部署/\":[{\"text\":\"基于VitePress+Github Pages详细v1.6.3\",\"link\":\"/vitepress/部署/VitePress+Github Pages详细v1.6.3\"},{\"text\":\"支持PC和wap自适应\",\"link\":\"/vitepress/部署/支持PC和wap自适应\"},{\"text\":\"dist部署\",\"link\":\"/vitepress/部署/dist部署\"},{\"text\":\"narbar单独抽离成文件\",\"link\":\"/vitepress/部署/narbar单独抽离成文件\"},{\"text\":\"sidebar单独抽离成文件\",\"link\":\"/vitepress/部署/sidebar单独抽离成文件\"},{\"text\":\"VitePress+Github Pages详细v1.6.3\",\"link\":\"/vitepress/部署/VitePress+Github Pages详细v1.6.3\"},{\"text\":\"VitePress部署\",\"link\":\"/vitepress/部署/VitePress部署\"},{\"text\":\"VitePress部署v1.6.3\",\"link\":\"/vitepress/部署/VitePress部署v1.6.3\"},{\"text\":\"VitePress从0到1\",\"link\":\"/vitepress/部署/VitePress从0到1\"}],\"/vuepress/\":[{\"text\":\"A_Node.js安装\",\"link\":\"/vuepress/A_Node.js安装.md\"},{\"text\":\"B_npm镜像站\",\"link\":\"/vuepress/B_npm镜像站\"},{\"text\":\"C_vuepress@1.9.10\",\"link\":\" /vuepress/C_vuepress@1.9.10\"},{\"text\":\"什么是敏感信息\",\"link\":\" /vuepress/什么是敏感信息\"}],\"/column/Algorithm/\":[{\"text\":\"栈和队列\",\"items\":[{\"text\":\"栈-深拷贝和浅拷贝\",\"link\":\"/column/Algorithm/001_Stack\"},{\"text\":\"队列-事件循环\",\"link\":\"/column/Algorithm/002_Queue\"}]},{\"text\":\"字典和树\",\"items\":[{\"text\":\"字典和集合-Set和Map\",\"link\":\"/column/Algorithm/003_Dictionary\"},{\"text\":\"树-深/广度优先遍历\",\"link\":\"/column/Algorithm/004_Tree\"}]}]},\"lastUpdated\":{\"text\":\"Last Updated\",\"formatOptions\":{\"dateStyle\":\"full\"}},\"search\":{\"provider\":\"local\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/vuejs/vitepress\"}],\"footer\":{\"message\":\"Released under the MIT License.\",\"copyright\":\"Copyright © modern\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>